# -*- coding: utf-8 -*-
"""projectnlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18M-rolcwq_nD-TH2fiFtf0gt9LEuxhqU
"""

pip install emoji

import re
import pandas as pd
import numpy as np
import emoji
from collections import Counter
import matplotlib.pyplot as plt
from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

def date_time(s):
    pattern='^([0-9]+)(\/)([0-9]+)(\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'
    result=re.match(pattern, s)
    if result:
        return True
    else:    
      return False  

#extract contact 
def user(s):
  s=s.split("s")
  if len(s) == 2:
    return True
  else:
    return False


# Extract Message
def getMessage(line):
    splitline=line.split(' - ')
    datetime= splitline[0];
    date, time= datetime.split(', ')
    message="  ".join(splitline[1:])
    
    if user(message):
        splitmessage=message.split(": ")
        author=splitmessage[0]
        message="  ".join(splitline[1:])
    else:
        author=None
    return date, time, author, message



# data to keep the preprocess data
data=[]
conversation_data='diva.txt'
# to omit the code and all for numbers
with open(conversation_data, encoding="utf-8") as fp:
    fp.readline()
    messagesepration=[]
    date, time, author= None, None, None
    # read each line
    while True:
        line=fp.readline()
        if not line:
            break
        line=line.strip( )
        # to seprate date time message and author
        if date_time(line):
            if len(messagesepration)>0:
                data.append([date, time, author, ''.join(messagesepration)])
            messagesepration.clear()
            date, time, author, message = getMessage(line)
            messagesepration.append(message)
        else:
            messagesepration.append(line)

df=pd.DataFrame(data, columns=["Date", "Time", "user", "Message"])
df['Date']=pd.to_datetime(df['Date'])

import nltk
nltk.download('vader_lexicon')

data=df.dropna()
# sentimental analysis
from nltk.sentiment.vader import SentimentIntensityAnalyzer
sentiments=SentimentIntensityAnalyzer()
# for each message we are checking its sentiment
data["positive"]=[sentiments.polarity_scores(i)["pos"] for i in data["Message"]]
data["negative"]=[sentiments.polarity_scores(i)["neg"] for i in data["Message"]]
data["neutral"]=[sentiments.polarity_scores(i)["neu"] for i in data["Message"]]

data.head(678)